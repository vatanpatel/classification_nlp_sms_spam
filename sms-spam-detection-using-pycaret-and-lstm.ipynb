{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Welcome.\nThis is my first notebook on NLP. I have chosen the Hello World dataset for NLP\nThe dataset is from kaggle and can be found [here](https://www.kaggle.com/uciml/sms-spam-collection-dataset). \nThe orignal dataset is published by UCI machine learning repository and can be found [here](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection).\nThe SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages, tagged acording being ham (legitimate) or spam.\n\nThe files contain one message per line. Each line is composed by two columns: v1 contains the label (ham or spam) and v2 contains the raw text.\n\nOur aim is to build a machine learning model to be able to identify spam messages. This is similar to how gmail filtersspam emails in your inbox.\n\n# Agenda\n* Reading the data\n* Exploring the data\n* Cleaning the data\n* Vectorizing the data\n* Fit multinomial NB model\n* Fit all classifiers using Pycaret AutoML library\n* Fit a LSTM nnet\n* Compare results"},{"metadata":{},"cell_type":"markdown","source":"First we will import the necessary libraries:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nimport string\n\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set_style('whitegrid')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading the data\nWe will read the data using pandas read_csv command into the dataframe named 'messages'"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"messages = pd.read_csv('../input/sms-spam-collection-dataset/spam.csv', encoding='latin-1')\nmessages","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We only need the columns v1 and v2. We will select them from the dataframe and rename them."},{"metadata":{"trusted":true},"cell_type":"code","source":"messages = messages[['v1', 'v2']]\nmessages.columns = ['label', 'message']\nmessages","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explorating the data\n\n"},{"metadata":{},"cell_type":"markdown","source":"We first check for missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"messages.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that there are no missing values in our data.\nWe now check how many ham and spam messages do we have in our dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"messages.groupby('label').count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(messages['label'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that the data is imbalanced as we would expect. The number of spam messages are less as compared to ham messages.\nLet's see how many words do we have in each messages."},{"metadata":{"trusted":true},"cell_type":"code","source":"message_len = messages['message'].apply(lambda x: len(x.split()))\nmessage_len.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(message_len)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that most of our messages have less than 50 words with a mean at 15 words."},{"metadata":{},"cell_type":"markdown","source":"# Cleaning the data\n"},{"metadata":{},"cell_type":"markdown","source":"Let us first take an example of the 6th message. "},{"metadata":{"trusted":true},"cell_type":"code","source":"messages['message'][5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will convert all the words to lowercase so that our algorithm identifies 'Hello', 'hello' and 'HELLO' all as the same word.\nWe also have numbers and punctuations. We would like to remove all the non text data from the messages because we do not need them for our analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"review = messages['message'][5].lower()\nreview = re.sub('[^a-z]', ' ', review)\nreview","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will remove all the stopwords (words like 'a', 'there', 'to', 'for' etc) which do not help us in our analysis. You can read more about stopwords [here](https://en.wikipedia.org/wiki/Stop_word).\nWe also apply Stemming. This is the process of converting each word into its root word. You can read more about it [here](https://en.wikipedia.org/wiki/Stemming)."},{"metadata":{"trusted":true},"cell_type":"code","source":"review = review.split()\nreview = [ps.stem(word) for word in review if not word in stopwords.words('english')]\nreview = ' '.join(review)\nreview","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now the message looks clean. We would now apply all these steps to all of our messages. We would add all the cleaned messages in a list named corpus."},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus = []\nfor i in range(0, len(messages)):\n    review = messages['message'][i].lower()\n    review = re.sub('[^a-z]', ' ', review)\n    review = review.split()\n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)\n    \ncorpus","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Vectorizing the data\nConverting text data  to numeric data that the machine can understand. We will use Count Vectorizer here. We choose to create a maximum of 2500 feature words here. You can read more about count vectorizer [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features=2500)\nX = cv.fit_transform(corpus).toarray()\nX","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We also convert labels into binary numbers. "},{"metadata":{"trusted":true},"cell_type":"code","source":"messages['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = pd.get_dummies(messages['label']).iloc[:,1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see 0 is assigned to 'ham' and 1 is assigned to 'spam' messages."},{"metadata":{},"cell_type":"markdown","source":"# Modelling\n\nSo to start, I like to apply an autoML library to compare how the model is performing on all the available classifiers. I used pycaret library for this purpose. PyCaret is an open source, low-code machine learning library. It compares  models on all the required metrics. You can read and learn to apply pycaret [here](https://pycaret.org).\nLet's instal pycaret, setup our data and start comparing models."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pycaret","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pycaret.classification import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.DataFrame(X)\ndata['label'] = y\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = setup(data = data, target = 'label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_models()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that Logistic Regression and LightGBM outperform rest of the models. Therefore we choose to manually apply logistic regression model on our data. We will also manually apply the multinomial Naive Bayes classifier which has proven to perform well on NLP problems."},{"metadata":{},"cell_type":"markdown","source":"We split the data into training and testing set in the ratio 80:20."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 420)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We tune the hyperparameters of Logistic Regression model using Grid search cross validation. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nLR = LogisticRegression()\nparam_grid = {'C': np.logspace(-4, 4, 20), 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}\ngrid = GridSearchCV(LR,param_grid,refit=True,verbose=3, scoring = 'roc_auc')\ngrid.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We make predictions on the test dataset using the best hyperparameters obtained from the Grid search."},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_LR = grid.predict(x_test)\nproba_LR = grid.predict_proba(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we see how our model performed. We compare our data to the actual labels in the test set. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\nprint(classification_report(y_test,pred_LR))\nprint(confusion_matrix(y_test,pred_LR))\nprint('AUC score is: {}'.format(roc_auc_score(y_test, pred_LR)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfpr, tpf, thresholds = roc_curve(y_test, pred_LR)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's try Multinomial Naive Bayes model for our data. Since there are no hyperparameters, we can fit the model directly to our data."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nmodel_NB = MultinomialNB().fit(x_train, y_train)\npred_NB = model_NB.predict(x_test)\nproba_NB = model_NB.predict_proba(x_test)\nprint(classification_report(y_test,pred_NB))\nprint(confusion_matrix(y_test,pred_NB))\nprint('AUC score is: {}'.format(roc_auc_score(y_test, pred_NB)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the LGBM classifier, we use the parameters provided by our pycaret model.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"model_LGBM = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n               importance_type='split', learning_rate=0.1, max_depth=-1,\n               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n               random_state=420, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n               subsample=1.0, subsample_for_bin=200000, subsample_freq=0).fit(x_train, y_train)\npred_LGBM = model_LGBM.predict(x_test)\nproba_LGBM = model_LGBM.predict_proba(x_test)\nprint(classification_report(y_test,pred_LGBM))\nprint(confusion_matrix(y_test,pred_LGBM))\nprint('AUC score is: {}'.format(roc_auc_score(y_test, pred_LGBM)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now apply LSTM nnet using techniques like embedding and padding to our corpus."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"voc_size = 10000\nonehot_repr=[one_hot(words,voc_size)for words in corpus] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sent_length=60\nembedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_vector_features=40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(100))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_final=np.array(embedded_docs)\ny_final=np.array(pd.get_dummies(messages['label']).iloc[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_final.shape,y_final.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.2, random_state=420)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)\nmodel.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000, callbacks=[early_stop])\n          \n          ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_LSTM=model.predict_classes(X_test)\nprint(classification_report(y_test,pred_LSTM))\nprint(confusion_matrix(y_test,pred_LSTM))\nprint('AUC score is: {}'.format(roc_auc_score(y_test, pred_LSTM)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Comparing the models:\nAccording to the results, Naive Bayes model performed best in classifying spam messages. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}